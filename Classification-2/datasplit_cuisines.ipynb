{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8492777-004f-4e54-839e-b3264088ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('cuisines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd05b37b-fb11-4126-9fe5-43e9582d6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and label extraction\n",
    "# Assumes 'cuisine' is the label column\n",
    "X = df.drop('cuisine', axis=1)\n",
    "y = df['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5658736-89d5-4d88-8588-0e5b80697710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc2d0cc-f552-4ad4-a53f-eb2ab78077c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97147667-936e-4249-a2fc-d6668cae725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000),  # Increased iterations\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME')  # Future-proofing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa49b93-605b-4a9a-86c4-ad69268de26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== KNN ======================\n",
      "Accuracy: 0.7361\n",
      "Precision (weighted): 0.7501\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.61      0.63      0.62       145\n",
      "      indian       0.82      0.90      0.86       177\n",
      "    japanese       0.70      0.50      0.58        88\n",
      "      korean       0.72      0.88      0.79       229\n",
      "        thai       0.96      0.46      0.62        96\n",
      "\n",
      "    accuracy                           0.74       735\n",
      "   macro avg       0.76      0.67      0.69       735\n",
      "weighted avg       0.75      0.74      0.73       735\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 92  11   5  36   1]\n",
      " [  8 159   0   9   1]\n",
      " [ 14   5  44  25   0]\n",
      " [ 16   2   9 202   0]\n",
      " [ 21  17   5   9  44]]\n",
      "\n",
      "====================== Logistic Regression ======================\n",
      "Accuracy: 0.8054\n",
      "Precision (weighted): 0.8042\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.71      0.76      0.73       145\n",
      "      indian       0.90      0.92      0.91       177\n",
      "    japanese       0.67      0.59      0.63        88\n",
      "      korean       0.84      0.88      0.86       229\n",
      "        thai       0.81      0.70      0.75        96\n",
      "\n",
      "    accuracy                           0.81       735\n",
      "   macro avg       0.78      0.77      0.77       735\n",
      "weighted avg       0.80      0.81      0.80       735\n",
      "\n",
      "Confusion Matrix:\n",
      "[[110   5   9  16   5]\n",
      " [  8 162   1   2   4]\n",
      " [ 14   1  52  17   4]\n",
      " [ 14   3   8 201   3]\n",
      " [ 10   9   8   2  67]]\n",
      "\n",
      "====================== SVM ======================\n",
      "Accuracy: 0.7823\n",
      "Precision (weighted): 0.7889\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.80      0.70      0.74       145\n",
      "      indian       0.72      0.93      0.81       177\n",
      "    japanese       0.77      0.45      0.57        88\n",
      "      korean       0.80      0.88      0.84       229\n",
      "        thai       0.89      0.70      0.78        96\n",
      "\n",
      "    accuracy                           0.78       735\n",
      "   macro avg       0.80      0.73      0.75       735\n",
      "weighted avg       0.79      0.78      0.77       735\n",
      "\n",
      "Confusion Matrix:\n",
      "[[101  18   3  21   2]\n",
      " [  3 165   2   3   4]\n",
      " [ 12  10  40  24   2]\n",
      " [  9  15   3 202   0]\n",
      " [  2  21   4   2  67]]\n",
      "\n",
      "====================== Random Forest ======================\n",
      "Accuracy: 0.9075\n",
      "Precision (weighted): 0.9107\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.82      0.90      0.86       145\n",
      "      indian       0.91      0.99      0.95       177\n",
      "    japanese       0.97      0.70      0.82        88\n",
      "      korean       0.95      0.98      0.96       229\n",
      "        thai       0.92      0.79      0.85        96\n",
      "\n",
      "    accuracy                           0.91       735\n",
      "   macro avg       0.91      0.87      0.89       735\n",
      "weighted avg       0.91      0.91      0.91       735\n",
      "\n",
      "Confusion Matrix:\n",
      "[[130   6   2   6   1]\n",
      " [  0 175   0   0   2]\n",
      " [ 16   1  62   5   4]\n",
      " [  3   2   0 224   0]\n",
      " [  9   9   0   2  76]]\n",
      "\n",
      "====================== AdaBoost ======================\n",
      "Accuracy: 0.8503\n",
      "Precision (weighted): 0.8572\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.75      0.79      0.77       145\n",
      "      indian       0.99      0.77      0.87       177\n",
      "    japanese       0.62      0.58      0.60        88\n",
      "      korean       0.85      1.00      0.92       229\n",
      "        thai       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           0.85       735\n",
      "   macro avg       0.84      0.83      0.83       735\n",
      "weighted avg       0.86      0.85      0.85       735\n",
      "\n",
      "Confusion Matrix:\n",
      "[[114   0  31   0   0]\n",
      " [  0 136   0  41   0]\n",
      " [ 37   0  51   0   0]\n",
      " [  0   1   0 228   0]\n",
      " [  0   0   0   0  96]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n====================== {name} ======================\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision (weighted): {prec:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, preds, target_names=le.classes_, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53922fe4-e3cd-40a1-9a1d-35741ea5fb12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
